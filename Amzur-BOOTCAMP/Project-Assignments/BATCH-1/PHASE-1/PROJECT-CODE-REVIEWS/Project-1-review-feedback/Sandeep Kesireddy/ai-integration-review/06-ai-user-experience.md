# AI User Experience & Frontend Integration Review

## Overview

This review evaluates the user experience and frontend integration of AI capabilities in the AIChatBot application. The quality of AI-powered user interfaces significantly impacts user adoption, satisfaction, and the overall effectiveness of AI features.

## AI Interface Design & Implementation

### Current Implementation

The AIChatBot implements a simple but functional chat interface using Streamlit:

```python
# Page title and configuration
st.set_page_config(page_title="AI ChatBot", page_icon="ðŸ¤–", layout="centered")
st.title("AI ChatBot ðŸ¤–")

# LLM provider selection
llm_provider = st.selectbox(
    "Choose LLM Provider:", ["openai", "gemini"], index=0, key="llm_provider"
)

# Chat input at bottom of page
prompt = st.chat_input("Type your message...", key="chat_input")

# Display chat history with simple styling
for msg in messages:
    safe_content = html.escape(msg["content"]).replace("\n", "<br>")
    if msg["role"] == "user":
        st.markdown(
            f"<div style='background:#e6f7ff;padding:10px 16px;border-radius:8px;"
            f"margin-bottom:10px;'><b>User:</b><br>{safe_content}</div>",
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            f"<div style='background:#f6ffe6;padding:10px 16px;border-radius:8px;"
            f"margin-bottom:16px;'><b>Assistant:</b><br>{safe_content}</div>",
            unsafe_allow_html=True,
        )
```

The interface includes:
- User ID input field for identifying sessions
- Provider selection dropdown (OpenAI or Gemini)
- Chat input box at the bottom
- Message bubbles with different colors for user and assistant
- Clear chat and feedback buttons

### Key Issues

1. **Limited UI Components**: Basic styling without rich UI components for AI interactions.

2. **No AI-Specific UI Elements**: Missing typing indicators, thinking states, or AI-specific controls.

3. **Limited Response Formatting**: No special formatting for different content types (code, tables, etc.).

4. **Basic User Identification**: Simple user ID input without proper session management.

5. **Limited Provider Customization**: Only provider selection without model or parameter controls.

## Real-Time AI Interaction

### Current Implementation

The application implements a synchronous request-response model with a loading spinner:

```python
with st.spinner("Thinking..."):
    try:
        resp = httpx.post(
            backend_url,
            json={
                "message": clean_prompt,
                "provider": llm_provider,
                "user_id": user_id,
            },
            timeout=20,
        )
        # ...process response...
```

### Key Issues

1. **No Streaming Responses**: Responses are only displayed when fully complete.

2. **Missing Real-Time Indicators**: No typing indicators or partial response display.

3. **No WebSocket Integration**: Uses HTTP requests instead of WebSockets for real-time communication.

4. **Long Wait Times**: Users must wait for the entire response with only a spinner as feedback.

5. **No Interrupt Capability**: No way to stop a generation in progress.

## Loading States & User Feedback

### Current Implementation

The application uses Streamlit's built-in spinner for loading states:

```python
with st.spinner("Thinking..."):
    # API call happens here
```

Error handling provides some feedback to users:

```python
except httpx.TimeoutException:
    st.warning(
        "The request timed out. Please check your "
        "network connection and try again."
    )
except httpx.HTTPStatusError as e:
    if e.response.status_code == 429:
        st.warning(
            "You have reached the chat rate limit. "
            "Please wait a minute and "
            "try again."
        )
```

### Key Issues

1. **Limited Loading Indicators**: Simple spinner without progress information.

2. **No Response Time Estimates**: No indication of expected wait times.

3. **Basic Error Feedback**: Generic error messages without specific recovery guidance.

4. **No Progress Updates**: No updates during long-running operations.

5. **Missing Processing Indicators**: No indication of what's happening during processing.

## AI Content Presentation & Formatting

### Current Implementation

The frontend presents AI-generated content with basic HTML formatting:

```python
safe_content = html.escape(msg["content"]).replace("\n", "<br>")
st.markdown(
    f"<div style='background:#f6ffe6;padding:10px 16px;border-radius:8px;"
    f"margin-bottom:16px;'><b>Assistant:</b><br>{safe_content}</div>",
    unsafe_allow_html=True,
)
```

### Key Issues

1. **Limited Content Formatting**: Simple line break conversion without rich formatting.

2. **No Markdown Rendering**: No proper rendering of markdown syntax.

3. **No Code Highlighting**: Code blocks are displayed as plain text.

4. **Limited Media Support**: No support for images or other media types.

5. **Missing Structured Content**: No special handling for structured data like tables or lists.

## User Control & Customization

### Current Implementation

The application offers minimal user control through:

```python
# LLM provider selection
llm_provider = st.selectbox(
    "Choose LLM Provider:", ["openai", "gemini"], index=0, key="llm_provider"
)

# Clear chat button
if st.button("ðŸ§¹ Clear Chat", help="Clear the conversation history"):
    try:
        resp = httpx.post(
            "http://localhost:8000/history/clear",
            json={"user_id": user_id},
            timeout=10,
        )
        resp.raise_for_status()
    except Exception:
        pass
    st.rerun()
```

### Key Issues

1. **Limited AI Customization**: Only provider selection without parameter controls.

2. **No Conversation Management**: No way to save, name, or manage conversations.

3. **Limited User Preferences**: No settings for response length, style, or format.

4. **No History Navigation**: No way to navigate or search conversation history.

5. **Missing Personalization**: No personalization options for AI interactions.

## Accessibility & Inclusive Design

### Current Implementation

The application has limited accessibility features:

```python
# Basic HTML structure with minimal accessibility
st.markdown(
    f"<div style='background:#f6ffe6;padding:10px 16px;border-radius:8px;"
    f"margin-bottom:16px;'><b>Assistant:</b><br>{safe_content}</div>",
    unsafe_allow_html=True,
)
```

### Key Issues

1. **Limited Semantic Structure**: HTML without proper ARIA attributes or semantic elements.

2. **Missing Keyboard Navigation**: No explicit keyboard navigation support.

3. **No Screen Reader Optimization**: No specific screen reader considerations.

4. **Limited Color Contrast**: Color scheme not explicitly tested for contrast.

5. **No Accessibility Settings**: No options to adjust text size, contrast, or other accessibility features.

## AI UX Quality Metrics

| Metric | Score | Assessment |
|--------|-------|------------|
| Usability | 6/10 | Basic but functional chat interface |
| Real-Time Interaction | 3/10 | No streaming or real-time feedback |
| Loading Experience | 4/10 | Basic spinner without detailed progress |
| Content Presentation | 4/10 | Simple content display without rich formatting |
| User Control | 4/10 | Limited customization and control options |
| Accessibility | 3/10 | Minimal accessibility considerations |

**Overall AI UX Score: 4.0/10 (POOR)**

## AI UX Improvement Recommendations

### 1. Implement Streaming Responses

Add real-time streaming responses for better user experience:

```python
# filepath: frontend/app.py

import html
import streamlit as st
import httpx
import os
from dotenv import load_dotenv
import json
import time
import re

# ... existing code ...

# Enhanced chat input with streaming response
if prompt and user_id:
    clean_prompt = prompt.strip()
    if not clean_prompt:
        st.warning("Please enter a non-empty message.")
    elif len(clean_prompt) > 1000:
        st.warning("Message too long. Please keep it under 1000 characters.")
    elif any(
        bad in clean_prompt.lower()
        for bad in ["<script", "<iframe", "</", "javascript:"]
    ):
        st.warning(
            "Input contains potentially unsafe content. "
            "Please remove any HTML or script tags."
        )
    else:
        # Add user message to UI immediately
        st.session_state.setdefault("messages", [])
        st.session_state.messages.append({"role": "user", "content": clean_prompt})
        
        # Display user message
        st.markdown(
            f"<div style='background:#e6f7ff;padding:10px 16px;border-radius:8px;"
            f"margin-bottom:10px;'><b>User:</b><br>{html.escape(clean_prompt).replace('\n', '<br>')}</div>",
            unsafe_allow_html=True,
        )
        
        # Create placeholder for assistant response
        response_placeholder = st.empty()
        response_placeholder.markdown(
            f"<div style='background:#f6ffe6;padding:10px 16px;border-radius:8px;"
            f"margin-bottom:16px;'><b>Assistant:</b><br>"
            f"<div class='typing-indicator'>Thinking<span class='dot1'>.</span><span class='dot2'>.</span><span class='dot3'>.</span></div></div>",
            unsafe_allow_html=True,
        )
        
        # Stream response from backend (this requires backend streaming support)
        try:
            # For the streaming version, we need to modify backend to support streaming
            # For now, we'll simulate streaming with chunked response handling
            
            # Initial placeholder content
            current_response = ""
            
            # Make API request
            resp = httpx.post(
                backend_url,
                json={
                    "message": clean_prompt,
                    "provider": llm_provider,
                    "user_id": user_id,
                    "stream": True,  # Request streaming (needs backend support)
                },
                timeout=30,
            )
            resp.raise_for_status()
            
            # If backend doesn't yet support streaming, we can simulate with chunked display
            # of the full response to demonstrate the UX improvement
            full_response = resp.json()["reply"]
            
            # Simulate streaming by displaying response chunks
            for i in range(min(len(full_response), 20)):  # Chunk into ~20 pieces
                chunk_end = (i + 1) * (len(full_response) // 20)
                if i == 19:  # Last chunk
                    chunk_end = len(full_response)
                current_response = full_response[:chunk_end]
                
                # Update placeholder with current response
                formatted_content = format_ai_response(current_response)
                response_placeholder.markdown(
                    f"<div style='background:#f6ffe6;padding:10px 16px;border-radius:8px;"
                    f"margin-bottom:16px;'><b>Assistant:</b><br>{formatted_content}</div>",
                    unsafe_allow_html=True,
                )
                
                # Small delay to simulate typing
                time.sleep(0.05)  # Adjust based on response length
            
            # Save final response to session
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
            # Update history from backend to ensure consistency
            try:
                resp_hist = httpx.get(
                    "http://localhost:8000/history",
                    params={"user_id": user_id},
                    timeout=10,
                )
                resp_hist.raise_for_status()
                messages = [
                    {"role": m["role"], "content": m["message"]}
                    for m in resp_hist.json().get("history", [])
                ]
            except Exception:
                pass
                
        except Exception as e:
            # Handle errors
            response_placeholder.error(f"Error: {str(e)}")
        
        # Clear input after processing
        st.session_state.chat_input = ""

# Helper function to format AI responses with enhanced styling
def format_ai_response(text):
    """Format AI response with better styling for code, lists, etc."""
    # Escape HTML to prevent injection
    content = html.escape(text)
    
    # Format code blocks with syntax highlighting
    def replace_code_block(match):
        language = match.group(1) or "text"
        code = match.group(2)
        return (
            f'<div class="code-block" style="background:#f0f0f0;border-radius:5px;margin:10px 0;">'
            f'<div style="background:#e0e0e0;padding:5px;border-top-left-radius:5px;border-top-right-radius:5px;font-weight:bold;">{language}</div>'
            f'<pre style="padding:10px;overflow-x:auto;"><code>{code}</code></pre>'
            f'</div>'
        )
    
    # Replace markdown code blocks ```language\ncode\n```
    content = re.sub(r'```(\w*)\n(.*?)\n```', replace_code_block, content, flags=re.DOTALL)
    
    # Replace inline code `code`
    content = re.sub(
        r'`([^`]+)`', 
        r'<code style="background:#f0f0f0;padding:2px 4px;border-radius:3px;">\1</code>', 
        content
    )
    
    # Format bullet lists
    def replace_bullet_list(match):
        list_content = match.group(0)
        items = re.findall(r'^\s*[\*\-]\s+(.+)$', list_content, re.MULTILINE)
        return '<ul style="margin-left:20px;">' + ''.join([f'<li>{item}</li>' for item in items]) + '</ul>'
    
    content = re.sub(r'(^|\n)[\*\-]\s+.+(\n[\*\-]\s+.+)*', replace_bullet_list, content)
    
    # Format numbered lists
    def replace_numbered_list(match):
        list_content = match.group(0)
        items = re.findall(r'^\s*\d+\.\s+(.+)$', list_content, re.MULTILINE)
        return '<ol style="margin-left:20px;">' + ''.join([f'<li>{item}</li>' for item in items]) + '</ol>'
    
    content = re.sub(r'(^|\n)\d+\.\s+.+(\n\d+\.\s+.+)*', replace_numbered_list, content)
    
    # Convert line breaks
    content = content.replace('\n', '<br>')
    
    return content

# Add custom CSS for better styling
st.markdown("""
<style>
.typing-indicator {
    display: inline-flex;
    align-items: center;
}
.dot1, .dot2, .dot3 {
    animation: pulse 1.5s infinite;
    margin-left: 2px;
}
.dot2 {
    animation-delay: 0.2s;
}
.dot3 {
    animation-delay: 0.4s;
}
@keyframes pulse {
    0% { opacity: 0.2; }
    50% { opacity: 1; }
    100% { opacity: 0.2; }
}
.chat-container {
    display: flex;
    flex-direction: column;
    height: calc(100vh - 150px);
}
.messages-container {
    flex: 1;
    overflow-y: auto;
    padding: 10px;
}
.input-container {
    padding: 10px;
    background: white;
    border-top: 1px solid #e0e0e0;
}
</style>
""", unsafe_allow_html=True)
```

### 2. Enhance Content Formatting and Display

Improve the presentation of AI-generated content:

```python
# filepath: frontend/content_formatter.py

import re
import html
import markdown

class ContentFormatter:
    @staticmethod
    def format_markdown(text):
        """Convert markdown to HTML with enhanced formatting"""
        # Process code blocks with syntax highlighting
        def process_code_blocks(match):
            lang = match.group(1) or "text"
            code = match.group(2)
            return f'<pre class="code-block language-{lang}"><code>{html.escape(code)}</code></pre>'
        
        # Replace code blocks before markdown conversion
        text = re.sub(r'```(\w*)\n(.*?)\n```', process_code_blocks, text, flags=re.DOTALL)
        
        # Convert markdown to HTML
        html_content = markdown.markdown(
            text,
            extensions=['tables', 'fenced_code', 'nl2br']
        )
        
        return html_content
    
    @staticmethod
    def format_bot_response(text):
        """Format bot response for display"""
        # First escape HTML to prevent XSS
        safe_text = html.escape(text)
        
        # Handle code blocks with syntax highlighting
        def replace_code_block(match):
            language = match.group(1) or "text"
            code = match.group(2)
            return (
                f'<div class="code-block">'
                f'<div class="code-header">{language}</div>'
                f'<pre><code>{code}</code></pre>'
                f'</div>'
            )
        
        # Replace markdown code blocks
        content = re.sub(r'```(\w*)\n(.*?)\n```', replace_code_block, safe_text, flags=re.DOTALL)
        
        # Handle inline code
        content = re.sub(r'`([^`]+)`', r'<code>\1</code>', content)
        
        # Handle bullet lists
        bullet_list_pattern = r'(?:\n|^)(?:\* .*\n)+'
        for match in re.finditer(bullet_list_pattern, content):
            bullet_list = match.group(0)
            items = re.findall(r'\* (.*)', bullet_list)
            html_list = '<ul>' + ''.join([f'<li>{item}</li>' for item in items]) + '</ul>'
            content = content.replace(bullet_list, html_list)
        
        # Handle numbered lists
        numbered_list_pattern = r'(?:\n|^)(?:\d+\. .*\n)+'
        for match in re.finditer(numbered_list_pattern, content):
            numbered_list = match.group(0)
            items = re.findall(r'\d+\. (.*)', numbered_list)
            html_list = '<ol>' + ''.join([f'<li>{item}</li>' for item in items]) + '</ol>'
            content = content.replace(numbered_list, html_list)
        
        # Replace line breaks with <br> tags
        content = content.replace('\n', '<br>')
        
        return content
```

### 3. Implement User Configuration and Customization

Add user settings and preferences for AI interactions:

```python
# filepath: frontend/ai_settings.py

import streamlit as st
from typing import Dict, Any

class AISettings:
    """Manage AI settings and preferences for the chatbot"""
    
    # Default settings
    DEFAULT_SETTINGS = {
        "model": {
            "openai": "gpt-3.5-turbo",
            "gemini": "gemini-pro"
        },
        "temperature": 0.7,
        "max_tokens": 500,
        "theme": {
            "user_bubble": "#e6f7ff",
            "assistant_bubble": "#f6ffe6"
        },
        "display": {
            "code_highlighting": True,
            "markdown_rendering": True,
            "streaming": True,
        },
        "accessibility": {
            "high_contrast": False,
            "large_text": False,
            "reduced_motion": False
        }
    }
    
    @staticmethod
    def initialize_settings():
        """Initialize settings in session state if not already present"""
        if "ai_settings" not in st.session_state:
            st.session_state.ai_settings = AISettings.DEFAULT_SETTINGS.copy()
    
    @staticmethod
    def save_settings(settings: Dict[str, Any]):
        """Save updated settings to session state"""
        st.session_state.ai_settings = settings
    
    @staticmethod
    def get_settings() -> Dict[str, Any]:
        """Get current settings from session state"""
        AISettings.initialize_settings()
        return st.session_state.ai_settings
    
    @staticmethod
    def display_settings_ui():
        """Display settings UI in Streamlit"""
        AISettings.initialize_settings()
        settings = st.session_state.ai_settings
        
        st.header("AI Chat Settings")
        
        # Model settings
        st.subheader("Model Settings")
        col1, col2 = st.columns(2)
        
        with col1:
            # Model selection for each provider
            settings["model"]["openai"] = st.selectbox(
                "OpenAI Model",
                ["gpt-3.5-turbo", "gpt-4"],
                index=0 if settings["model"]["openai"] == "gpt-3.5-turbo" else 1
            )
        
        with col2:
            settings["model"]["gemini"] = st.selectbox(
                "Gemini Model",
                ["gemini-pro", "gemini-ultra"],
                index=0 if settings["model"]["gemini"] == "gemini-pro" else 1
            )
        
        # Generation parameters
        st.subheader("Generation Parameters")
        settings["temperature"] = st.slider(
            "Temperature (Creativity)",
            min_value=0.0,
            max_value=1.0,
            value=settings["temperature"],
            step=0.1,
            help="Higher values make responses more creative, lower values make them more deterministic"
        )
        
        settings["max_tokens"] = st.slider(
            "Maximum Response Length",
            min_value=100,
            max_value=2000,
            value=settings["max_tokens"],
            step=100,
            help="Maximum length of the generated response"
        )
        
        # Display settings
        st.subheader("Display Settings")
        settings["display"]["code_highlighting"] = st.checkbox(
            "Enable Code Syntax Highlighting",
            value=settings["display"]["code_highlighting"]
        )
        
        settings["display"]["markdown_rendering"] = st.checkbox(
            "Enable Markdown Rendering",
            value=settings["display"]["markdown_rendering"]
        )
        
        settings["display"]["streaming"] = st.checkbox(
            "Enable Response Streaming",
            value=settings["display"]["streaming"],
            help="Show responses as they're being generated"
        )
        
        # Accessibility settings
        st.subheader("Accessibility Settings")
        settings["accessibility"]["high_contrast"] = st.checkbox(
            "High Contrast Mode",
            value=settings["accessibility"]["high_contrast"]
        )
        
        settings["accessibility"]["large_text"] = st.checkbox(
            "Large Text Mode",
            value=settings["accessibility"]["large_text"]
        )
        
        settings["accessibility"]["reduced_motion"] = st.checkbox(
            "Reduced Motion",
            value=settings["accessibility"]["reduced_motion"],
            help="Disable animations for reduced motion sensitivity"
        )
        
        # Reset button
        if st.button("Reset to Defaults"):
            st.session_state.ai_settings = AISettings.DEFAULT_SETTINGS.copy()
            st.success("Settings reset to defaults")
            st.rerun()
        
        # Save settings
        AISettings.save_settings(settings)
        
        return settings
```

### 4. Implement Conversation Management

Add conversation management and organization:

```python
# filepath: frontend/conversation_manager.py

import streamlit as st
import httpx
import time
from datetime import datetime
from typing import List, Dict, Any

class ConversationManager:
    """Manage chat conversations, history, and metadata"""
    
    @staticmethod
    def initialize():
        """Initialize conversation state if not present"""
        if "conversations" not in st.session_state:
            st.session_state.conversations = {}
        
        if "current_conversation" not in st.session_state:
            st.session_state.current_conversation = "default"
    
    @staticmethod
    def create_new_conversation(title: str = None):
        """Create a new conversation and make it active"""
        # Generate a unique ID
        conversation_id = f"conv_{int(time.time())}"
        
        # Use timestamp as default title if none provided
        if not title:
            title = f"Conversation {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        
        # Create conversation object
        st.session_state.conversations[conversation_id] = {
            "id": conversation_id,
            "title": title,
            "created_at": datetime.now().isoformat(),
            "messages": [],
            "metadata": {
                "provider": st.session_state.get("llm_provider", "openai"),
                "user_id": st.session_state.get("user_id", "default")
            }
        }
        
        # Set as current conversation
        st.session_state.current_conversation = conversation_id
        
        return conversation_id
    
    @staticmethod
    def switch_conversation(conversation_id: str):
        """Switch to a different conversation"""
        if conversation_id in st.session_state.conversations:
            st.session_state.current_conversation = conversation_id
            return True
        return False
    
    @staticmethod
    def get_current_conversation() -> Dict[str, Any]:
        """Get the current active conversation"""
        ConversationManager.initialize()
        
        # If there are no conversations, create default one
        if not st.session_state.conversations:
            ConversationManager.create_new_conversation("Default Conversation")
        
        # Return the current conversation
        current_id = st.session_state.current_conversation
        return st.session_state.conversations.get(current_id, {})
    
    @staticmethod
    def get_all_conversations() -> List[Dict[str, Any]]:
        """Get all conversations"""
        ConversationManager.initialize()
        
        # Convert dict to sorted list (newest first)
        conversations = list(st.session_state.conversations.values())
        conversations.sort(key=lambda c: c.get("created_at", ""), reverse=True)
        
        return conversations
    
    @staticmethod
    def rename_conversation(conversation_id: str, new_title: str):
        """Rename an existing conversation"""
        if conversation_id in st.session_state.conversations:
            st.session_state.conversations[conversation_id]["title"] = new_title
            return True
        return False
    
    @staticmethod
    def delete_conversation(conversation_id: str):
        """Delete a conversation"""
        if conversation_id in st.session_state.conversations:
            # Delete from state
            del st.session_state.conversations[conversation_id]
            
            # If deleted conversation was current, switch to another one
            if st.session_state.current_conversation == conversation_id:
                if st.session_state.conversations:
                    st.session_state.current_conversation = next(iter(st.session_state.conversations))
                else:
                    # Create a new default conversation if none left
                    ConversationManager.create_new_conversation("New Conversation")
            
            return True
        return False
    
    @staticmethod
    def add_message_to_current(role: str, content: str):
        """Add a message to the current conversation"""
        conversation = ConversationManager.get_current_conversation()
        conversation_id = conversation.get("id")
        
        if conversation_id:
            # Add message to conversation
            message = {
                "role": role,
                "content": content,
                "timestamp": datetime.now().isoformat()
            }
            
            st.session_state.conversations[conversation_id]["messages"].append(message)
            
            # Update backend if needed (syncing local state with server)
            user_id = conversation.get("metadata", {}).get("user_id", "default")
            try:
                backend_messages = [
                    {"role": m["role"], "message": m["content"]}
                    for m in st.session_state.conversations[conversation_id]["messages"]
                ]
                
                # This would be a real API call to sync with backend
                # For now, it's just a placeholder
                # httpx.post("http://localhost:8000/history/sync", json={
                #     "user_id": user_id,
                #     "conversation_id": conversation_id,
                #     "messages": backend_messages
                # })
                pass
            except Exception as e:
                print(f"Error syncing with backend: {e}")
            
            return True
        return False
    
    @staticmethod
    def display_conversation_sidebar():
        """Display conversation management sidebar UI"""
        ConversationManager.initialize()
        
        st.sidebar.title("Conversations")
        
        # New conversation button
        if st.sidebar.button("âž• New Conversation"):
            ConversationManager.create_new_conversation()
            st.rerun()
        
        # List all conversations
        conversations = ConversationManager.get_all_conversations()
        current_id = st.session_state.current_conversation
        
        for conv in conversations:
            conv_id = conv["id"]
            title = conv["title"]
            
            # Format as current if selected
            if conv_id == current_id:
                st.sidebar.markdown(f"**â†’ {title}**")
            else:
                # Create a button styled as a link
                if st.sidebar.button(f"{title}", key=f"conv_{conv_id}"):
                    ConversationManager.switch_conversation(conv_id)
                    st.rerun()
            
            # Show actions in an expander
            with st.sidebar.expander("Actions", expanded=False):
                # Rename conversation
                new_title = st.text_input("New title:", value=title, key=f"rename_{conv_id}")
                if st.button("Rename", key=f"btn_rename_{conv_id}"):
                    ConversationManager.rename_conversation(conv_id, new_title)
                    st.rerun()
                
                # Delete conversation
                if st.button("ðŸ—‘ï¸ Delete", key=f"delete_{conv_id}"):
                    if ConversationManager.delete_conversation(conv_id):
                        st.rerun()
```

### 5. Implement Accessibility Enhancements

Add improved accessibility features:

```python
# filepath: frontend/accessibility.py

import streamlit as st
from typing import Dict, Any

class AccessibilityManager:
    """Manage accessibility features for the chatbot UI"""
    
    @staticmethod
    def apply_accessibility_settings(settings: Dict[str, Any]):
        """Apply accessibility settings to the UI"""
        accessibility = settings.get("accessibility", {})
        
        # Build CSS based on accessibility settings
        css = []
        
        # High contrast mode
        if accessibility.get("high_contrast", False):
            css.extend([
                """
                .user-message {
                    background-color: #073642 !important;
                    color: #fdf6e3 !important;
                    border: 2px solid #2aa198 !important;
                }
                .assistant-message {
                    background-color: #002b36 !important;
                    color: #fdf6e3 !important;
                    border: 2px solid #268bd2 !important;
                }
                .stButton>button {
                    background-color: #073642 !important;
                    color: #fdf6e3 !important;
                    border: 1px solid #2aa198 !important;
                }
                body {
                    color: #fdf6e3 !important;
                    background-color: #002b36 !important;
                }
                """
            ])
        
        # Large text mode
        if accessibility.get("large_text", False):
            css.extend([
                """
                body {
                    font-size: 1.2rem !important;
                }
                .stTextInput>div>div>input {
                    font-size: 1.2rem !important;
                }
                .user-message, .assistant-message {
                    font-size: 1.2rem !important;
                }
                """
            ])
        
        # Reduced motion
        if accessibility.get("reduced_motion", False):
            css.extend([
                """
                * {
                    animation-duration: 0.001s !important;
                    transition-duration: 0.001s !important;
                }
                .typing-indicator, .dot1, .dot2, .dot3 {
                    animation: none !important;
                }
                """
            ])
        
        # Add additional accessibility features
        css.extend([
            """
            /* Improve keyboard focus indicators */
            :focus {
                outline: 3px solid #2aa198 !important;
                outline-offset: 2px !important;
            }
            
            /* Better link contrast */
            a, a:visited {
                color: #268bd2 !important;
                text-decoration: underline !important;
            }
            
            /* Make chat bubbles more distinguishable */
            .user-message, .assistant-message {
                margin-bottom: 16px !important;
                border-radius: 8px !important;
                padding: 12px 16px !important;
            }
            
            /* ARIA landmark regions */
            .header-region {
                role: "banner";
            }
            .main-content {
                role: "main";
            }
            .chat-input {
                role: "form";
                aria-label: "Chat message input";
            }
            """
        ])
        
        # Apply CSS
        if css:
            st.markdown(f"<style>{''.join(css)}</style>", unsafe_allow_html=True)
    
    @staticmethod
    def add_accessibility_features_to_elements():
        """Add accessibility attributes to HTML elements"""
        # This requires JavaScript integration which is limited in Streamlit
        # But we can add some basic accessibility improvements through HTML attributes
        
        # Add screen reader only instructions
        st.markdown(
            """
            <div class="sr-only" style="position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);border:0;">
                Chat interface. Use tab key to navigate between elements. Press Enter to send messages.
            </div>
            """, 
            unsafe_allow_html=True
        )
    
    @staticmethod
    def format_message_for_accessibility(role: str, content: str) -> str:
        """Format message content with accessibility attributes"""
        role_label = "User" if role == "user" else "AI Assistant"
        
        # Add appropriate ARIA roles and labels
        if role == "user":
            return f"""
            <div class="user-message" role="listitem" aria-label="User message">
                <span class="sr-only">Message from: {role_label}</span>
                <div><strong>{role_label}:</strong></div>
                <div>{content}</div>
            </div>
            """
        else:
            return f"""
            <div class="assistant-message" role="listitem" aria-label="Assistant message">
                <span class="sr-only">Message from: {role_label}</span>
                <div><strong>{role_label}:</strong></div>
                <div>{content}</div>
            </div>
            """
```

### 6. Implement Enhanced Error States and Recovery

Add better error handling and recovery:

```python
# filepath: frontend/error_handler.py

import streamlit as st
import httpx
from typing import Dict, Any, Optional, Tuple

class ErrorHandler:
    """Handle errors and provide user recovery options"""
    
    # Error categories
    NETWORK_ERRORS = (httpx.ConnectError, httpx.ConnectTimeout, httpx.ReadTimeout)
    AUTH_ERRORS = (401, 403)
    RATE_LIMIT_ERRORS = (429,)
    SERVER_ERRORS = (500, 502, 503, 504)
    
    @staticmethod
    def handle_api_error(
        error: Exception, 
        retry_callback: Optional[callable] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        Handle API errors with user-friendly messages and recovery options
        
        Returns:
            Tuple[str, Dict]: (error_message, recovery_options)
        """
        error_message = ""
        recovery_options = {}
        
        # Network connectivity errors
        if isinstance(error, ErrorHandler.NETWORK_ERRORS):
            error_message = (
                "Unable to connect to the AI service. Please check your internet connection "
                "and try again."
            )
            recovery_options = {
                "retry": {
                    "label": "Try Again",
                    "callback": retry_callback,
                    "primary": True
                },
                "offline_mode": {
                    "label": "Continue in Offline Mode",
                    "callback": lambda: st.session_state.update({"offline_mode": True})
                }
            }
            
        # HTTP status code errors
        elif isinstance(error, httpx.HTTPStatusError):
            status_code = error.response.status_code
            
            # Authentication errors
            if status_code in ErrorHandler.AUTH_ERRORS:
                error_message = (
                    "Authentication failed. The AI service API key may be invalid or expired."
                )
                recovery_options = {
                    "settings": {
                        "label": "Check API Settings",
                        "callback": lambda: st.session_state.update({"show_settings": True}),
                        "primary": True
                    }
                }
                
            # Rate limiting errors
            elif status_code in ErrorHandler.RATE_LIMIT_ERRORS:
                error_message = (
                    "You've reached the rate limit for AI requests. Please wait a moment "
                    "before trying again."
                )
                recovery_options = {
                    "retry": {
                        "label": "Try Again Later",
                        "callback": retry_callback
                    },
                    "switch_provider": {
                        "label": "Try Different AI Provider",
                        "callback": lambda: st.session_state.update({"show_provider_switch": True}),
                        "primary": True
                    }
                }
                
            # Server errors
            elif status_code in ErrorHandler.SERVER_ERRORS:
                error_message = (
                    "The AI service is currently experiencing issues. Please try again later "
                    "or switch to a different provider."
                )
                recovery_options = {
                    "retry": {
                        "label": "Try Again",
                        "callback": retry_callback
                    },
                    "switch_provider": {
                        "label": "Switch AI Provider",
                        "callback": lambda: st.session_state.update({"show_provider_switch": True}),
                        "primary": True
                    }
                }
                
            # Other HTTP errors
            else:
                error_message = (
                    f"Unexpected error (HTTP {status_code}): {error.response.text[:100]}... "
                    f"Please try again or contact support."
                )
                recovery_options = {
                    "retry": {
                        "label": "Try Again",
                        "callback": retry_callback,
                        "primary": True
                    }
                }
                
        # Generic error fallback
        else:
            error_message = f"An unexpected error occurred: {str(error)[:100]}..."
            recovery_options = {
                "retry": {
                    "label": "Try Again",
                    "callback": retry_callback,
                    "primary": True
                }
            }
        
        return error_message, recovery_options
    
    @staticmethod
    def display_error_ui(
        error_message: str, 
        recovery_options: Dict[str, Any],
        container=None
    ):
        """
        Display error message with recovery options
        
        Args:
            error_message: User-friendly error message
            recovery_options: Dictionary of recovery options with callbacks
            container: Optional Streamlit container to render in
        """
        # Use provided container or st directly
        ui = container if container else st
        
        # Display error in visually distinct way
        ui.error(error_message)
        
        # Create columns for buttons based on number of options
        num_options = len(recovery_options)
        if num_options > 0:
            cols = ui.columns(num_options)
            
            # Add recovery option buttons
            for i, (option_id, option) in enumerate(recovery_options.items()):
                # Determine if button should be primary
                is_primary = option.get("primary", False)
                button_type = "primary" if is_primary else "secondary"
                
                # Create button with appropriate styling
                if cols[i].button(
                    option["label"],
                    key=f"recovery_{option_id}_{hash(error_message)}",
                    type=button_type
                ):
                    # Execute callback if defined
                    callback = option.get("callback")
                    if callback and callable(callback):
                        callback()
```

## User Experience Conclusion

The AIChatBot's current user experience implementation is basic but functional. While it provides the essential chat interface features, it lacks sophisticated AI-specific UI elements, real-time feedback, and advanced content formatting that would significantly enhance the user experience.

By implementing the recommended improvements, the application would gain:

1. **Real-Time Interaction**: Through streaming responses and typing indicators
2. **Rich Content Presentation**: Via markdown rendering and code highlighting
3. **User Customization**: With AI parameter controls and preferences
4. **Better Organization**: Through conversation management and navigation
5. **Improved Accessibility**: With enhanced accessibility features and controls

These improvements would transform the AI user experience quality from POOR to GOOD or EXCELLENT, making the application more engaging, responsive, and user-friendly. By better leveraging Streamlit's capabilities and implementing AI-specific UI patterns, the AIChatBot can deliver a much more sophisticated and satisfying user experience.
